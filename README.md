# mupify

Important notes:
 * In your architecture, use ReLU layers (i.e., use nn.ReLU() and not torch.functional.relu)